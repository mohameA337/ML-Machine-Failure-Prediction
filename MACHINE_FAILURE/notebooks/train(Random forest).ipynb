{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e206e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da32944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed_data.csv\")\n",
    "X = df.drop(\"fail\", axis=1)\n",
    "y = df[\"fail\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044118fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(params):\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_split=params[\"min_samples_split\"],\n",
    "        min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "        random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5b3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
    "    }\n",
    "\n",
    "    model = my_model(params)\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"cv_accuracy\", score)\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84073c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-20 20:43:32,700] A new study created in memory with name: no-name-2b8fd674-cb15-44d7-bc00-ce1cffae93d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:43:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:43:41,675] Trial 0 finished with value: 0.9112649929382997 and parameters: {'n_estimators': 148, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.9112649929382997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run funny-shrew-775 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/a119f262f03b4a6592b80f1d6c3f4d22\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:43:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:43:48,468] Trial 1 finished with value: 0.9165612681548936 and parameters: {'n_estimators': 293, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9165612681548936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nervous-gnat-844 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/420fc69311ff4dee83e2ceacc20266ed\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:43:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:43:54,561] Trial 2 finished with value: 0.9152279769809649 and parameters: {'n_estimators': 153, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9165612681548936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run beautiful-fowl-154 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/f83b71a97497407198f56cad7974a3ad\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:00,185] Trial 3 finished with value: 0.9085984105904424 and parameters: {'n_estimators': 93, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9165612681548936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run skillful-fly-472 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/a4fccfae657842178bee44566c66bb85\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:06,018] Trial 4 finished with value: 0.9178787495520563 and parameters: {'n_estimators': 149, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run fearless-kite-750 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/af8f8e893f01498892ae88e6b3dd07e8\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:11,798] Trial 5 finished with value: 0.9112544530871224 and parameters: {'n_estimators': 78, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nimble-moth-867 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/7637a05610424730bd4bdb933b9a0c80\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:18,148] Trial 6 finished with value: 0.9165612681548936 and parameters: {'n_estimators': 212, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run legendary-calf-207 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/c2fd33a62a37468ca0f65043a3d3ee11\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:24,561] Trial 7 finished with value: 0.9152385168321423 and parameters: {'n_estimators': 174, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run caring-sheep-997 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/dafa2e5f59784339aa47f4c0a52791fb\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:30,760] Trial 8 finished with value: 0.9139157655093909 and parameters: {'n_estimators': 156, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run redolent-squid-680 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/e7aa4a40c19b47cf9d35448d9348bc4c\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:36,680] Trial 9 finished with value: 0.9125877442610509 and parameters: {'n_estimators': 200, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run awesome-whale-732 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/fbf69ece2ec34ab1903b88a8e1a19146\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:43,356] Trial 10 finished with value: 0.9152385168321423 and parameters: {'n_estimators': 292, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run clean-fawn-869 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/fae36b47812f4b7eaf0ee19ab30b7d8b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:50,046] Trial 11 finished with value: 0.9165612681548936 and parameters: {'n_estimators': 298, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run big-crow-672 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/36de1da4770c413eaf65673913d782f1\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:44:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:44:56,275] Trial 12 finished with value: 0.9125824743354624 and parameters: {'n_estimators': 237, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run capricious-shrew-848 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/2b2d2ed55bfa4b77b35e3363ce71701f\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:02,377] Trial 13 finished with value: 0.908603680516031 and parameters: {'n_estimators': 247, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run amusing-hawk-952 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/585a05244aef480eae30bae2d89db9f7\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:07,956] Trial 14 finished with value: 0.9125772044098737 and parameters: {'n_estimators': 113, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nosy-lamb-41 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/ccc5b675919e44bcbd42b93468eb2fcd\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:13,733] Trial 15 finished with value: 0.9152332469065536 and parameters: {'n_estimators': 121, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run valuable-worm-501 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/37ae326555234a33b090f9a04cd76e50\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:19,134] Trial 16 finished with value: 0.9139104955838023 and parameters: {'n_estimators': 57, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run enthused-zebra-113 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/b7dfb0fad4a349688d7fc9154ecc0bce\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:25,462] Trial 17 finished with value: 0.9139104955838023 and parameters: {'n_estimators': 266, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run masked-snake-32 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/be608398be4e4ae5a985977023a9717c\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:31,807] Trial 18 finished with value: 0.9139104955838023 and parameters: {'n_estimators': 198, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run rebellious-sloth-569 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/67e7ee16c032406eb2a58dc60bb50f17\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:45:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 20:45:37,936] Trial 19 finished with value: 0.9139104955838023 and parameters: {'n_estimators': 125, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9178787495520563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run lyrical-ram-712 at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/3407b67458d449d5b6ecce45f833e4ea\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n",
      "Best Accuracy: 0.9178787495520563\n",
      "Best Params: {'n_estimators': 149, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Machine_Failure_Prediction\")\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best Accuracy:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97391e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:47:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.8783068783068783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       102\n",
      "           1       0.86      0.87      0.87        87\n",
      "\n",
      "    accuracy                           0.88       189\n",
      "   macro avg       0.88      0.88      0.88       189\n",
      "weighted avg       0.88      0.88      0.88       189\n",
      "\n",
      "ðŸƒ View run Final_Model at: http://127.0.0.1:5000/#/experiments/931066514622847259/runs/22774c912f054b328d839d99a77a1c55\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/931066514622847259\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# === Load Scaler ===\n",
    "with open(os.path.join(\"data\", \"scaler.pkl\"), \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# === Define the model class exactly as trained ===\n",
    "class myNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout):\n",
    "        super(myNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# === Instantiate model and load weights ===\n",
    "input_dim = 9\n",
    "hidden_dim = 64      # change if needed\n",
    "dropout = 0.3        # change if needed\n",
    "model = myNN(input_dim, hidden_dim, dropout)\n",
    "\n",
    "model_path = os.path.join(\"notebooks\", \"weight.pt\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "model.eval()\n",
    "\n",
    "# === FastAPI setup ===\n",
    "app = FastAPI(title=\"Machine Failure Prediction (PyTorch)\")\n",
    "\n",
    "# === Input schema ===\n",
    "class SensorData(BaseModel):\n",
    "    footfall: float\n",
    "    AQ: float\n",
    "    USS: float\n",
    "    CS: float\n",
    "    VOC: float\n",
    "    RP: float\n",
    "    IP: float\n",
    "    Temperature: float\n",
    "    tempMode: float\n",
    "\n",
    "# === Inference endpoint ===\n",
    "@app.post(\"/predict/pytorch\")\n",
    "def predict(data: SensorData):\n",
    "    # Convert input to numpy â†’ scale â†’ tensor\n",
    "    input_array = np.array([[\n",
    "        data.footfall, data.AQ, data.USS, data.CS,\n",
    "        data.VOC, data.RP, data.IP, data.Temperature, data.tempMode\n",
    "    ]])\n",
    "    scaled = scaler.transform(input_array)\n",
    "    input_tensor = torch.tensor(scaled, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = model(input_tensor)\n",
    "        pred = int((prob > 0.5).item())\n",
    "\n",
    "    return {\n",
    "        \"model\": \"pytorch\",\n",
    "        \"prediction\": pred,\n",
    "        \"status\": \"failure risk\" if pred == 1 else \"normal\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faecfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
