{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e93845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ace685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed_data.csv\")\n",
    "\n",
    "X = df.drop(\"fail\", axis=1).values\n",
    "y = df[\"fail\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa489fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  \n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)    \n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63ea5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout):\n",
    "        super(myNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eb154aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())  # should now be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02550213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    " \n",
    "    params = {\n",
    "        \"hidden_dim\": trial.suggest_int(   \"hidden_dim\", 32, 128 ),\n",
    "        \"lr\":         trial.suggest_float( \"lr\", 1e-4, 1e-2, log=True ),\n",
    "        \"dropout\":    trial.suggest_float( \"dropout\", 0.1, 0.5 ),\n",
    "        \"epochs\":     trial.suggest_int(   \"epochs\", 5, 15 )\n",
    "    }\n",
    "\n",
    "    model     = myNN(X_train.shape[1], params[\"hidden_dim\"], params[\"dropout\"])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        for epoch in range(params[\"epochs\"]):\n",
    "            model.train()\n",
    "            running_train_loss = 0\n",
    "            all_train_preds = []\n",
    "            all_train_labels = []\n",
    "\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                batch_y = batch_y.float()  \n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_train_loss += loss.item()\n",
    "                preds = (outputs > 0.5).int()\n",
    "                all_train_preds.append(preds)\n",
    "                all_train_labels.append(batch_y.int())\n",
    "\n",
    "            all_train_preds = torch.cat(all_train_preds).squeeze()\n",
    "            all_train_labels = torch.cat(all_train_labels).squeeze()\n",
    "            train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
    "            avg_train_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_test_tensor)\n",
    "                val_loss = criterion(val_outputs, y_test_tensor)\n",
    "                val_pred = (val_outputs > 0.5).int().squeeze()\n",
    "                val_acc = accuracy_score(y_test_tensor.int(), val_pred)\n",
    "\n",
    "            \n",
    "            mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss.item(), step=epoch)\n",
    "            mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "            mlflow.pytorch.log_model(model,\"model\")\n",
    "            \n",
    "\n",
    "        return val_loss  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "402c2e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-20 22:18:01,899] A new study created in memory with name: no-name-45bb353e-c27e-4ba4-8442-d27797803d6f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:18:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:18:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:18:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:18:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:18:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:18:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:18:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:19:45,148] Trial 0 finished with value: 0.4426933228969574 and parameters: {'hidden_dim': 95, 'lr': 0.007088332593357684, 'dropout': 0.17267723114027023, 'epochs': 14}. Best is trial 0 with value: 0.4426933228969574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run abundant-newt-576 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/01ecf338190548798d54671e66f473f6\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:19:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:19:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:20:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:20:58,198] Trial 1 finished with value: 0.4664183259010315 and parameters: {'hidden_dim': 52, 'lr': 0.0001647181899069437, 'dropout': 0.21159596657027105, 'epochs': 10}. Best is trial 0 with value: 0.4426933228969574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run burly-shark-927 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/250dc54e490f465b8ff8d29ba69c0989\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:21:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:21:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:21:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:21:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:21:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:21:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:21:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:22:31,145] Trial 2 finished with value: 0.3450113832950592 and parameters: {'hidden_dim': 119, 'lr': 0.0023084395677269247, 'dropout': 0.35892996592629245, 'epochs': 12}. Best is trial 2 with value: 0.3450113832950592.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run delicate-asp-681 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/07edb6a8d5aa4c508c0fc43f45522362\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:22:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:22:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:23:16,246] Trial 3 finished with value: 0.33978429436683655 and parameters: {'hidden_dim': 88, 'lr': 0.001548128443854572, 'dropout': 0.13546016106226128, 'epochs': 6}. Best is trial 3 with value: 0.33978429436683655.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run fortunate-bear-994 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/b95932576eca4784a40c991a72257703\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:23:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:23:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:24:04,024] Trial 4 finished with value: 0.3330089747905731 and parameters: {'hidden_dim': 118, 'lr': 0.0006785734470005471, 'dropout': 0.36644781044051566, 'epochs': 6}. Best is trial 4 with value: 0.3330089747905731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run masked-robin-951 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/bf2139805ce04d6c83c0e6fb36852bd8\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:24:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:24:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:25:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:25:53,959] Trial 5 finished with value: 0.3653879463672638 and parameters: {'hidden_dim': 95, 'lr': 0.004800063400327459, 'dropout': 0.4324050082291616, 'epochs': 14}. Best is trial 4 with value: 0.3330089747905731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run dazzling-grub-415 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/587322e8e32b4a57a39ed1b61d206190\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:26:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:26:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:27:32,762] Trial 6 finished with value: 0.38138845562934875 and parameters: {'hidden_dim': 94, 'lr': 0.004356653167199393, 'dropout': 0.14837322289682434, 'epochs': 13}. Best is trial 4 with value: 0.3330089747905731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run capable-crow-83 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/b3b8d9111c7b4867a35fc37c3d81b73b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:27:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:27:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:28:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:29:16,644] Trial 7 finished with value: 0.34006673097610474 and parameters: {'hidden_dim': 49, 'lr': 0.0005019938203960943, 'dropout': 0.10868996671426956, 'epochs': 14}. Best is trial 4 with value: 0.3330089747905731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run languid-fly-488 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/e13af4b3eacd4f2bb5af0158beb7b1ad\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:29:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:29:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:30:41,461] Trial 8 finished with value: 0.2996259331703186 and parameters: {'hidden_dim': 63, 'lr': 0.0004616241109278588, 'dropout': 0.30733626716433937, 'epochs': 11}. Best is trial 8 with value: 0.2996259331703186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run sassy-dog-632 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/50900bb5a2ae42b791c167aeb8bf5c34\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:30:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:30:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:31:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:31:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:31:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:31:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:31:29,266] Trial 9 finished with value: 0.29904383420944214 and parameters: {'hidden_dim': 112, 'lr': 0.0014292302869352298, 'dropout': 0.36657419275172154, 'epochs': 6}. Best is trial 9 with value: 0.29904383420944214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nosy-crow-976 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/9528bc2509f6428593bde80c27767b8d\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:31:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:31:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:31:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:32:33,626] Trial 10 finished with value: 0.34736430644989014 and parameters: {'hidden_dim': 124, 'lr': 0.0001481657252836465, 'dropout': 0.25427910973032064, 'epochs': 8}. Best is trial 9 with value: 0.29904383420944214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run luminous-worm-2 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/64dcc7428fcb44f199e4c502c8c8860b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:32:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:32:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:33:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:33:51,880] Trial 11 finished with value: 0.32365578413009644 and parameters: {'hidden_dim': 68, 'lr': 0.00035677375398350384, 'dropout': 0.4989930403998569, 'epochs': 10}. Best is trial 9 with value: 0.29904383420944214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run orderly-whale-594 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/aefe2c36f9a842aa810357c0d1fc4568\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:33:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:34:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:34:54,904] Trial 12 finished with value: 0.34218040108680725 and parameters: {'hidden_dim': 71, 'lr': 0.0010601112739950574, 'dropout': 0.32799450438158023, 'epochs': 8}. Best is trial 9 with value: 0.29904383420944214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run wise-fly-779 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/159dc6b0c7e840b2b880d12ed9bb724d\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:35:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:35:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:35:59,987] Trial 13 finished with value: 0.4719289541244507 and parameters: {'hidden_dim': 33, 'lr': 0.0002887922632222424, 'dropout': 0.26613177058189635, 'epochs': 8}. Best is trial 9 with value: 0.29904383420944214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run hilarious-stoat-637 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/bd258e53667d452db94b04568d260157\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 22:36:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:36:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:36:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:36:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 22:36:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-05-20 22:36:38,708] Trial 14 finished with value: 0.2937333285808563 and parameters: {'hidden_dim': 71, 'lr': 0.0016109145194270799, 'dropout': 0.43305797500170606, 'epochs': 5}. Best is trial 14 with value: 0.2937333285808563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run painted-dove-177 at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/44e70b5085b84114a4d7523cbaddc6a4\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n",
      "ðŸƒ View run Optuna_PyTorch at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/8687945d17af43e09f006b1860694171\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n",
      "Best trial: 0.2937333285808563\n",
      "Best params: {'hidden_dim': 71, 'lr': 0.0016109145194270799, 'dropout': 0.43305797500170606, 'epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Machine_Failure_PyTorch\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "with mlflow.start_run(run_name=\"Optuna_PyTorch\"):\n",
    "    study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best trial:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c3687f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 23:34:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9285\n",
      "Final Test Accuracy: 0.8783\n",
      "ðŸƒ View run Final_PyTorch_Model at: http://127.0.0.1:5000/#/experiments/820496218632962888/runs/77f2510b94304b7584da6896cf8eb187\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/820496218632962888\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "final_model = myNN(X_train.shape[1], best_params[\"hidden_dim\"], best_params[\"dropout\"])\n",
    "final_model = final_model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"lr\"])\n",
    "\n",
    "for epoch in range(best_params[\"epochs\"]):\n",
    "    final_model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    train_outputs = final_model(X_train_tensor.to(device))\n",
    "    train_preds = (train_outputs > 0.5).int().squeeze()\n",
    "    train_acc = accuracy_score(y_train_tensor.cpu().int(), train_preds.cpu())\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs = final_model(X_test_tensor)\n",
    "    test_preds = (test_outputs > 0.5).int().squeeze()\n",
    "    test_acc = accuracy_score(y_test_tensor.cpu().int(), test_preds.cpu())\n",
    "\n",
    "with mlflow.start_run(run_name=\"Final_PyTorch_Model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_acc)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "    mlflow.pytorch.log_model(final_model, \"model\")\n",
    "\n",
    "    print(f\"Final Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "torch.save(final_model.state_dict(), \"model_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca83722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
